{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\nfrom transformers import MBartTokenizer, MBartForConditionalGeneration, Trainer, TrainingArguments\nimport torch\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-09-04T18:56:30.533126Z","iopub.execute_input":"2023-09-04T18:56:30.533842Z","iopub.status.idle":"2023-09-04T18:56:45.795729Z","shell.execute_reply.started":"2023-09-04T18:56:30.533788Z","shell.execute_reply":"2023-09-04T18:56:45.794775Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = \"facebook/mbart-large-50\"","metadata":{"execution":{"iopub.status.busy":"2023-09-04T18:57:43.867276Z","iopub.execute_input":"2023-09-04T18:57:43.867684Z","iopub.status.idle":"2023-09-04T18:57:43.872722Z","shell.execute_reply.started":"2023-09-04T18:57:43.867652Z","shell.execute_reply":"2023-09-04T18:57:43.871750Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/english-hinglish/English_Hinglish_Corpus.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-04T18:27:48.968040Z","iopub.execute_input":"2023-09-04T18:27:48.968781Z","iopub.status.idle":"2023-09-04T18:27:48.997462Z","shell.execute_reply.started":"2023-09-04T18:27:48.968745Z","shell.execute_reply":"2023-09-04T18:27:48.996446Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                             english  \\\n0       Are Barcelona playing today at the camp nou?   \n1      The last time we went to the USA was in 1994.   \n2  I am thinking about applying for the MS progra...   \n3    I think Stanford would be too expensive for me.   \n4                   I got my driver's license today.   \n\n                                            hinglish  \n0         क्या barcelona आज camp nou में खेल रहा है?  \n1                   आखिरी बार हम 1994 में USA गए थे।  \n2  मैं UC Berkley में MS program के लिए apply करन...  \n3  मुझे लगता है कि Stanform मेरे लिए बहुत महंगा ह...  \n4             मुझे आज अपना Driver's License मिल गया।  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english</th>\n      <th>hinglish</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Are Barcelona playing today at the camp nou?</td>\n      <td>क्या barcelona आज camp nou में खेल रहा है?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The last time we went to the USA was in 1994.</td>\n      <td>आखिरी बार हम 1994 में USA गए थे।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I am thinking about applying for the MS progra...</td>\n      <td>मैं UC Berkley में MS program के लिए apply करन...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I think Stanford would be too expensive for me.</td>\n      <td>मुझे लगता है कि Stanform मेरे लिए बहुत महंगा ह...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I got my driver's license today.</td>\n      <td>मुझे आज अपना Driver's License मिल गया।</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataset = data.to_dict(orient='records')","metadata":{"execution":{"iopub.status.busy":"2023-09-04T18:27:48.999121Z","iopub.execute_input":"2023-09-04T18:27:48.999469Z","iopub.status.idle":"2023-09-04T18:27:49.006064Z","shell.execute_reply.started":"2023-09-04T18:27:48.999437Z","shell.execute_reply":"2023-09-04T18:27:49.005122Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenizer = MBartTokenizer.from_pretrained(model_name)\nmodel = MBartForConditionalGeneration.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T18:27:55.809598Z","iopub.execute_input":"2023-09-04T18:27:55.809979Z","iopub.status.idle":"2023-09-04T18:28:24.061131Z","shell.execute_reply.started":"2023-09-04T18:27:55.809949Z","shell.execute_reply":"2023-09-04T18:28:24.060188Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b424b3371ea44109bc81a3c66f4591a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c8484fad8c14691aa86d1f3e72434df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/531 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d7da69d03b94d71b4980922bed8afab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9ce94e2ecf94577a95cadb1f47ff540"}},"metadata":{}},{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'MBart50Tokenizer'. \nThe class this function is called from is 'MBartTokenizer'.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"509ee47a1fe5468fb25d21a396f46489"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"201a93592123487994d4cd7d7991985d"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize and format your dataset\ntokenized_dataset = tokenizer.prepare_seq2seq_batch(src_texts=[item[\"english\"] for item in dataset], tgt_texts=[item[\"hinglish\"] for item in dataset], return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T18:28:24.063263Z","iopub.execute_input":"2023-09-04T18:28:24.063645Z","iopub.status.idle":"2023-09-04T18:28:24.110213Z","shell.execute_reply.started":"2023-09-04T18:28:24.063601Z","shell.execute_reply":"2023-09-04T18:28:24.109318Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3786: FutureWarning: \n`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n`__call__` method to prepare your inputs and targets.\n\nHere is a short example:\n\nmodel_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n\nIf you either need to use different keyword arguments for the source and target texts, you should do two calls like\nthis:\n\nmodel_inputs = tokenizer(src_texts, ...)\nlabels = tokenizer(text_target=tgt_texts, ...)\nmodel_inputs[\"labels\"] = labels[\"input_ids\"]\n\nSee the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\nFor a more complete example, see the implementation of `prepare_seq2seq_batch`.\n\n  warnings.warn(formatted_warning, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a custom dataset\nclass CustomDataset(Dataset):\n    def __init__(self, tokenized_dataset):\n        self.data = tokenized_dataset\n\n    def __len__(self):\n        return len(self.data[\"input_ids\"])\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": self.data[\"input_ids\"][idx],\n            \"attention_mask\": self.data[\"attention_mask\"][idx],\n            \"labels\": self.data[\"labels\"][idx]\n        }\n\ncustom_dataset = CustomDataset(tokenized_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T18:28:24.111547Z","iopub.execute_input":"2023-09-04T18:28:24.112130Z","iopub.status.idle":"2023-09-04T18:28:24.118964Z","shell.execute_reply.started":"2023-09-04T18:28:24.112098Z","shell.execute_reply":"2023-09-04T18:28:24.117973Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./fine-tuned-model\",\n    overwrite_output_dir=True,\n    num_train_epochs=2,\n    per_device_train_batch_size=2,\n    save_steps=10,\n    save_total_limit=1,\n)\n\n# Create a Trainer instance\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=None,  # Use the default data collator\n    train_dataset=custom_dataset,  # Provide the custom dataset\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T18:46:54.469839Z","iopub.execute_input":"2023-09-04T18:46:54.470422Z","iopub.status.idle":"2023-09-04T18:46:54.532308Z","shell.execute_reply.started":"2023-09-04T18:46:54.470389Z","shell.execute_reply":"2023-09-04T18:46:54.531155Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Start fine-tuning\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-04T18:46:55.294413Z","iopub.execute_input":"2023-09-04T18:46:55.294786Z","iopub.status.idle":"2023-09-04T18:51:30.453463Z","shell.execute_reply.started":"2023-09-04T18:46:55.294755Z","shell.execute_reply":"2023-09-04T18:51:30.451541Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [64/64 04:33, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=64, training_loss=1.9569430351257324, metrics={'train_runtime': 274.3453, 'train_samples_per_second': 0.467, 'train_steps_per_second': 0.233, 'total_flos': 16524364480512.0, 'train_loss': 1.9569430351257324, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Save the fine-tuned model\ntrainer.save_model(\"./fine-tuned-model\")","metadata":{"execution":{"iopub.status.busy":"2023-09-04T18:52:41.983332Z","iopub.execute_input":"2023-09-04T18:52:41.983806Z","iopub.status.idle":"2023-09-04T18:52:57.025707Z","shell.execute_reply.started":"2023-09-04T18:52:41.983767Z","shell.execute_reply":"2023-09-04T18:52:57.023537Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Load the fine-tuned model and tokenizer\nupd_model = MBartForConditionalGeneration.from_pretrained(\"/kaggle/working/fine-tuned-model\")\ntokenizer = MBartTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T18:59:49.184738Z","iopub.execute_input":"2023-09-04T18:59:49.185730Z","iopub.status.idle":"2023-09-04T19:00:22.012154Z","shell.execute_reply.started":"2023-09-04T18:59:49.185682Z","shell.execute_reply":"2023-09-04T19:00:22.011091Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'MBart50Tokenizer'. \nThe class this function is called from is 'MBartTokenizer'.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text_one = \"Definitely share your feedback in the comment section\"\ninput_text_two = \"So even if it's a big video, I will clearly mention all the products.\"\ninput_text_three = \"I was waiting for my bag.\"","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:04:59.751764Z","iopub.execute_input":"2023-09-04T19:04:59.752643Z","iopub.status.idle":"2023-09-04T19:04:59.760456Z","shell.execute_reply.started":"2023-09-04T19:04:59.752604Z","shell.execute_reply":"2023-09-04T19:04:59.758322Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"input_ids_one = tokenizer.encode(\"en_\" + input_text_one, return_tensors=\"pt\", max_length=1024, padding=\"max_length\", truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:05:01.561533Z","iopub.execute_input":"2023-09-04T19:05:01.562704Z","iopub.status.idle":"2023-09-04T19:05:01.570992Z","shell.execute_reply.started":"2023-09-04T19:05:01.562656Z","shell.execute_reply":"2023-09-04T19:05:01.569766Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"translation_one = upd_model.generate(input_ids_one, max_length=1024, num_return_sequences=1, decoder_start_token_id=upd_model.config.decoder_start_token_id)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:05:14.303725Z","iopub.execute_input":"2023-09-04T19:05:14.304348Z","iopub.status.idle":"2023-09-04T19:05:27.555404Z","shell.execute_reply.started":"2023-09-04T19:05:14.304313Z","shell.execute_reply":"2023-09-04T19:05:27.554248Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"translated_text_one = tokenizer.decode(translation_one[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:05:27.557448Z","iopub.execute_input":"2023-09-04T19:05:27.558175Z","iopub.status.idle":"2023-09-04T19:05:27.566078Z","shell.execute_reply.started":"2023-09-04T19:05:27.558138Z","shell.execute_reply":"2023-09-04T19:05:27.564999Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"input_ids_two = tokenizer.encode(\"en_\" + input_text_two, return_tensors=\"pt\", max_length=1024, padding=\"max_length\", truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:05:30.892666Z","iopub.execute_input":"2023-09-04T19:05:30.893750Z","iopub.status.idle":"2023-09-04T19:05:30.900596Z","shell.execute_reply.started":"2023-09-04T19:05:30.893701Z","shell.execute_reply":"2023-09-04T19:05:30.899287Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"translation_two = upd_model.generate(input_ids_two, max_length=1024, num_return_sequences=1, decoder_start_token_id=upd_model.config.decoder_start_token_id)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translated_text_two = tokenizer.decode(translation_two[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:08:02.343216Z","iopub.status.idle":"2023-09-04T19:08:02.344779Z","shell.execute_reply.started":"2023-09-04T19:08:02.344526Z","shell.execute_reply":"2023-09-04T19:08:02.344550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids_three = tokenizer.encode(\"en_\" + input_text_three, return_tensors=\"pt\", max_length=1024, padding=\"max_length\", truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:08:08.034523Z","iopub.execute_input":"2023-09-04T19:08:08.034933Z","iopub.status.idle":"2023-09-04T19:08:08.042111Z","shell.execute_reply.started":"2023-09-04T19:08:08.034900Z","shell.execute_reply":"2023-09-04T19:08:08.041004Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"translation_three = upd_model.generate(input_ids_three, max_length=1024, num_return_sequences=1, decoder_start_token_id=upd_model.config.decoder_start_token_id)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:08:09.475723Z","iopub.execute_input":"2023-09-04T19:08:09.477118Z","iopub.status.idle":"2023-09-04T19:08:21.787161Z","shell.execute_reply.started":"2023-09-04T19:08:09.477073Z","shell.execute_reply":"2023-09-04T19:08:21.786097Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"translated_text_three = tokenizer.decode(translation_three[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:08:21.789243Z","iopub.execute_input":"2023-09-04T19:08:21.789620Z","iopub.status.idle":"2023-09-04T19:08:21.797986Z","shell.execute_reply.started":"2023-09-04T19:08:21.789585Z","shell.execute_reply":"2023-09-04T19:08:21.796926Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(\"The translated texts are:\")\nprint(\"1)\" + translated_text_one)\n# print(\"2)\" + translated_text_two)\nprint(\"3)\" + translated_text_three)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:09:16.255449Z","iopub.execute_input":"2023-09-04T19:09:16.255883Z","iopub.status.idle":"2023-09-04T19:09:16.265855Z","shell.execute_reply.started":"2023-09-04T19:09:16.255844Z","shell.execute_reply":"2023-09-04T19:09:16.264726Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"The translated texts are:\n1)आपकी feedback को comment section में जरूर share करें।\n3)मैं उसे bag waiting करने के लिए waiting कर रहा था।\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}